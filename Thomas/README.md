# Lightweight Object Detection in Satellite Imagery

## Abstract 

Current efforts in conducting object detection in satellite imagery requires a strong base knowledge of Deep Learning frameworks and respectable computing resources. The ability to perform this type of analysis has matured significantly along with the concepts involved. Deep Learning application of object detection in satellite imagery presents a high cost of entry. This paper presents a Python program that serves as a lightweight solution to conducting object detection in satellite imagery and requires novice Deep Learning intuition and limited computing resources. 

## Introduction

The dynamic application of Deep Learning frameworks in the field of Computer Vision has evolved tremendously across domains. Computer Vision is a subset of artificial intelligence that aims at training computers to interpret images and gain a greater understanding of visual processes. This type of digital analysis is being explored by applying machine learning techniques to train algorithms that are capable of improving a human’s ability to process various images and conduct object detection on numerous types of targets. 

One domain of research and analysis that poses a need for this type of automation is the field of Geospatial Intelligence and in particular the application to satellite imagery. A large share of actionable intelligence within the Geospatial domain comes from the high-volume acquisition of overhead satellite imagery. The availability of commercial satellite imagery has grown exponentially over the last decade and has produced an enhanced ability to monitor the world at a heightened temporal rate. With the compounding collection of data comes the need to streamline the process of imagery analysis and object detection. 

Object detection in high resolution satellite imagery has been explored extensively over recent years and significant benchmarks have been set on improving the ability to detect high interest objects. Target objects typically include vehicles, roads, buildings and vessels. The innovation of vessel detection in high resolution satellite imagery over recent years has produced very high performing, pre-trained models that can be deployed within a user’s computing environment and applied to a personal use case. Though these high performing models produce benchmark results, they also require a significant amount of computing resources and a respectable degree of domain knowledge in Deep Learning frameworks. Analysts within the Geospatial Intelligence domain possess unique skills that allow them to reveal hidden insights in geographic clarity but may not possess the understanding of Deep Learning algorithms that is needed to conduct this type of analysis. 

The application presented in this paper will provide the capability to develop and deploy a simpler, more lightweight object detection model that produces accurate results and can be applied to open-source imagery. The user of this application will be able to either produce their own training data or import from another source, develop and train a Deep Learning model using the Keras framework, deploy the model to run predictions on desired imagery, and finally produce an object detection output with geographic attribution. This type of capability within GIS frameworks has been developed in proprietary software such as ArcGIS. However, the ability to conduct object detection is currently limited in open source GIS software such as QGIS. This application presents the capability to perform this type of analysis on an open source platform with minimal Deep Learning understanding using limited computing resources.

## Theoretical Framework

Deep Learning has grown in popularity in the development of artificial intelligence and has generated a significant interest throughout the tech community. Deep Learning as a concept often appears mystifying to those that have not developed a strong foundation in Data Science and Machine Learning. In general, Deep learning is like many other Machine Learning methods in that it takes input data and generates a prediction. The algorithm aims to understand the patterns shared between the inputs and outputs to then be able to generalize the input data that the model has yet to be introduced to. Deep Learning algorithms are composed of neural networks which comprise connections of input, hidden and output layers by nodes. Information is transferred between these layers and once the input is pushed to the output, the model is able to evaluate its performance and make adjustments to weights in the algorithm. 

One of the most popular and powerful Deep Learning methods in image processing is Convolutional Neural Networks (CNN). CNNs are able to analyze the importance of nearby pixels in an image by applying a filter of a specified dimension. A value is calculated for each pixel in the image using this filter process through a convolution operation. This type of operation is geared towards extracting features from an image. An early application of this is observed in handwritten digit recognition. A classically known dataset in Deep Learning is MNIST which is made up of 700,000 handwritten digits represented as a grayscale array of 28x28. CNNs have been extensively applied to this dataset. Kumar et.al. [1] compared other approaches to this classification problem by developing a 7-layer Keras sequential model for digit recognition and yielding improved results over other methods such as Hidden Markov model and Multilayer Perceptron. This approach shows the capability to classify image chips based on the features displayed in the pixel values. 

Modern application of Deep Learning in satellite imagery takes a more finite approach when it comes to object detection. The availability of very-high resolution satellite imagery has improved the ability the automatically process and analyze for various targets. Guo et.al. [2] showcase the ability to target multiple classes of objects in satellite imagery such as airplanes, vehicles, and baseball fields. This is partly made possible by large training datasets that have been compiled to create benchmark models in conducting object detection on many targets of interest. Rather than classifying an image chip, these benchmark datasets compile annotated images with bounding locations of various object. Guo et.al. proceed to execute a multi-scale CNN that combines the functionality of multiple object detection methods and presents the ability to detect objects location and size of bounding box for each object. 

The increased availability of higher resolution imagery, large training datasets, and heavily constructed pre-trained models has come with the need for robust computing resources and a strong understanding of Deep Learning application. The program presented in this paper leverages the simplicity and lightweight nature of a Keras Sequential model as presented in handwritten digit recognition. Rather than classifying image chips of digits, this model will display that ability to detect vessels in satellite imagery using a similar methodology. The technical cost of entry to conducting object detection is discounted and lends to an expanded user population. 

## Data and Methods

This paper presents the option to either utilize an existing dataset containing labeled features or create custom training data to fit the users particular use case. Labeled datasets can be found through various sources including this Kaggle competition. The approach taken in this research was to present the ability to create custom training images using simple techniques in open-source GIS software. Given a satellite image that contains that target object, in this case vessels, the user is enabled to label the known location of objects with a centroid point. A square buffer of desired radius is the created around each labeled point. The square bounding box feature is then used to clip the portions of the larger satellite image that contain the target object into individual image chips of the object. These image chips will serve as the positive labeled data. 

Next, a similar process is conducted to extract negative labeled images. Rather than labeling point locations of the target object, random points throughout the image are generated and the corresponding bounding box buffers are used to clip image chips of the larger satellite image. This process creates the negative labeled image chips that represent non-object background portions of the image. Given the generation or acquisition of training image chips the program developed in this project presents the capability to conduct object detection in satellite imagery using a collection of modules that allow the user to define the parameters of input data, develop the training data using the image chips, compiling and training a Deep Learning model, running model predictions across a satellite image using the trained model, and finally producing a geographically attributed dataset that contains bounding boxes of model predictions. 

First, the formation of training data is conducted using image chips. This is done by importing the images and cropping to consistent dimensions. Next, the user is given the option to augment the images. Augmenting consists of creating additional training data by transforming an image in a processing of flipping, rotating, and transposing. This process presents the ability to create a more robust training dataset by increasing the number of samples at varying orientations. The image chips are then converted to arrays of 8-bit integers that represent the pixel values. These arrays are also known as tensors. A separate array is then created that represents the binary labels of the training data as either containing the object or not containing the object. 

Next, the training tensors and labels are compiled, shuffled and split into training and testing data. Additionally, the data values are normalized to a scale of 255. A model is then defined and compiled. The model used in this program is a Keras sequential model with two fully connected Convolutional Neural Networks. This type of model is flexible and allows the user to customize the parameters, optimizers, activation techniques, and even add additional layers to tune the results of the model. The user will have control over customizing the model or optionally importing a pre-trained model that leverages benchmark results. The model is then trained on the pre-defined training data and optionally saved to avoid continuously training for similar application.

The trained model is now ready to be leveraged in conducting object detection in a desired satellite image. This program gives the user the option to import satellite images as targets for object detection or alternatively tap into an API to download imagery based on user defined parameters. The API utilized in this program provides access to satellite imagery captured by The European Space Agency Sentinel satellites. This imagery is open source with a valid login. Sentinel provides global imagery at 10-meter resolution. The API is accessed directly from the Python program and available imagery is queried by defining geographic bounds for searching, date range for image capture, as well as desired threshold for cloud cover percentage (typically desired to be <10%). The program is then automatically able to access the product list, download the associated products, and extract the 10-meter true color image from the zipped directory. 

With the satellite imagery either uploaded into the program or internally downloaded from the Sentinel API, the object detection portion of the program is prepared for initiation. The satellite image is first transformed into a tensor array of normalized 8-bit integers. The user is given the option to crop the image to specified geographic bounds prior to processing. Additionally, given the prior knowledge of areas to disregard in the image, a mask layer may be imported and applied to the satellite image. In the case of detecting vessels, a mask layer of land features may be imported to exclude non-water pixels from model consideration. An additional processing step may be performed that enhances processing speed in the form of image segmentation. Using K-Means Clustering algorithm, the image pixels can be grouped in n number of classes. This type of processing increases the efficiency of the object detection algorithm by isolating regions of the satellite image that likely contain the object and ignores other regions of the image such as water. 

The object detection function conducts predictions of the presence of the target object in the satellite image by implementing a moving window. The moving window essentially scans the image and uses the trained model to conduct a prediction on a portion of the image and continues to traverse until predictions have been made across the entire image. This can be an expensive process depending on how large the image is. The step size in which the window moves across the image may be adjusted to accommodate computing resources. If the prediction value of a window is greater than the user defined threshold, the location coordinates of the window are stored in a list. 

Assuming the successful detection of objects in the image, the list of coordinates will likely contain multiple positive predictions for the same object. To address the duplication of detections, each coordinate bounding box is analyzed relative to the overlapping bounding boxes. This is done by calculating the intersection over union (IOU) which is the amount of intersection area relative to the total area of the box. If two boxes have an IOU greater than a desired threshold, the two boxes are assumed to be detecting the same object. The box with the highest prediction score is then stored and the other is discarded. This is conducted for all potentially overlapping predictions to produce a final coordinates list. 

Finally, the trimmed results are converted to geographic features. This is done by referencing the original attribution of the satellite image such as geographic bounds, coordinate reference system, and image resolution. The final coordinates are converted into Well Known Text (WKT) strings which are formatted in a way that allows the storing of geographic attribution and ingestion by a GIS software program. 

## Results

One of the primary goals of this program is to provide a customizable yet simple platform to conduct object detection in satellite imagery with minimal knowledge of Deep Learning application. This goal is achieved with great success. The program requires limited user input in terms of parameters and is able to conduct a complete object detection operation with minimal computing resources. The results of the object detection are highly dependent upon the quality and volume of training data that is provided to the program. The program provides the user with the capability to save and compile training data to improve object detection accuracy. The speed at which the algorithm performs depends on the size of the satellite imagery being analyzed. The moving window predictions can be conducted on a 10-kilometer by 10-kilometer image at 10-meter resolution in approximately one minute. 

Most modern satellite image object detection benchmarks are achieved using very-high resolution sub-meter imagery which is often not publicly available and expensive to acquire. This program presents a completely open source solution to conducting object detection in satellite imagery with targeted object acquisition in custom training data creation. 

## Conclusion

10-meter, open source imagery is presented as an optional import in this program but the program itself is not limited to high resolution imagery. This program was tested using very-high resolution imagery (0.5-meter resolution) with great results. Given the availability of very-high resolution imagery, this program can be applied to detecting various objects aside from seaborn vessels. The spectral properties and geometric shapes of target objects can be learned the same by this type of algorithm and applied to objects such as airplanes, solar panels, or swimming pools. This program is also not limited to the simplicity of a Keras Sequential model. The framework put into place lends to the introduction of a pre-trained model that yields benchmark results and highly accurate masking of objects. 

Though the intention of this program is to be a light introduction to conducting object detection in satellite imagery at minimal computing cost, the foundation is formed to extend the program to state of the art techniques in computer vision and higher lever GPU processing. The tools to conduct object detection in satellite imagery exist in proprietary GIS software. This type of capability presents the notion that Deep Learning concepts in imagery analysis can be achieved across many levels of expertise at a significantly lower cost. 

## Next Steps

This program is delivered as a Python module that presents the capability to be executed from the command line. The code can be accessed directly to input custom parameters and utilize various pre-trained models. Though the module requires minimal user control aside from the processing parameters, the need for a software interface is apparent. The code infrastructure is in place to create a custom plugin for an open source GIS software called QGIS. The intentional progression of this project is to develop this capability into a more manageable solution in conducting common Geospatial analysis through a user interface directly deployed in QGIS.






